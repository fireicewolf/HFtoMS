{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fireicewolf/HFtoMS/blob/main/HFtoMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Mh-qYDMKX_Zu"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "!pip install --no-cache-dir -U huggingface-hub modelscope requests\n",
    "!pip cache purge\n",
    "!apt update && apt install aria2 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "G0U7KXTOX_Zw"
   },
   "outputs": [],
   "source": [
    "# @title Remove useless python package for more storage space.\n",
    "!pip uninstall tensorboard tensorboard-data-server tensorflow tensorflow-datasets tensorflow-estimator tensorflow-gcs-config tensorflow-hub tensorflow-io-gcs-filesystem tensorflow-metadata tensorflow-probability tensorstore -y\n",
    "!pip uninstall torch torchaudio torchsummary torchtext torchvision triton -y\n",
    "!pip uninstall opencv-python-headless opencv-python opencv-contrib-python -y\n",
    "!pip uninstall Sphinx sphinxcontrib-applehelp sphinxcontrib-devhelp sphinxcontrib-htmlhelp sphinxcontrib-jsmath sphinxcontrib-qthelp sphinxcontrib-serializinghtml -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "22OBweJZX_Zx"
   },
   "outputs": [],
   "source": [
    "# @title Cleanup workspace\n",
    "%cd /content\n",
    "!rm -rf /content/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_-9nOJhrX_Zy"
   },
   "outputs": [],
   "source": [
    "#@title HF to MS\n",
    "from typing import Literal\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from huggingface_hub import HfApi,login, list_repo_tree, hf_hub_download\n",
    "from huggingface_hub.hf_api import RepoFile, RepoFolder\n",
    "\n",
    "from modelscope.hub.api import HubApi\n",
    "from modelscope.hub.constants import ModelVisibility\n",
    "\n",
    "WORKSPACE = \"/content\"\n",
    "WORK_MODE = \"Fork single file from Huggingface to Modelscope\" # @param {\"type\":\"string\"} [\"Fork repo from Huggingface to Modelscope\",\"Fork single file from Huggingface to Modelscope\",\"Download single file from CivitAI to Modelscope\"]\n",
    "#@markdown Fork repo from HuggingFace\n",
    "HF_TOKEN = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Your HF_TOKEN\"}\n",
    "HF_REPO_ID = \"\" # @param {type:\"string\",\"placeholder\":\"HF Repo ID you want to fork\"}\n",
    "HF_RECURSIVE = True # @param {type:\"boolean\"}\n",
    "HF_REPO_TYPE = \"model\" # @param [\"model\",\"space\",\"dataset\"]\n",
    "HF_REVISION = \"main\" # @param {type:\"string\",\"placeholder\":\"HF Repo REVISION\"}\n",
    "#@markdown Download Single file from HuggingFace\n",
    "HF_SUBFOLDER = \"\" # @param {\"type\":\"string\",\"placeholder\":\"HF subfolder name\"}\n",
    "HF_FILENAME = \"\" # @param {type:\"string\",\"placeholder\":\"HF single file name\"}\n",
    "#@markdown CIVITAI download\n",
    "CIVITAI_TOKEN = \"\" # @param {\"type\":\"string\",\"placeholder\":\"CivitAI_TOKEN\"}\n",
    "DOWNLOAD_LINK = \"\" # @param {\"type\":\"string\",\"placeholder\":\"CivitAI Link\"}\n",
    "DOWNLOAD_FILENAME = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Download file name\"}\n",
    "#@markdown Modelscope settings\n",
    "MS_TOKEN = \"\" # @param {type:\"string\",\"placeholder\":\"Your MS_TOKEN\"}\n",
    "MS_REPO_ID = \"\" # @param {type:\"string\",\"placeholder\":\"MS Repo ID you want to create/upload\"}\n",
    "MS_REPO_PRIVATE = True # @param {type:\"boolean\",\"placeholder\":\"MS Repo visibility\"}\n",
    "MS_REVISION = \"master\" # @param {type:\"string\",\"placeholder\":\"MS Repo REVISION\"}\n",
    "MS_COMMIT = \"Upload to ModelScope\" # @param {type:\"string\",\"placeholder\":\"MS Repo commit message\"}\n",
    "#@markdown Modelscope AIGC repo settings\n",
    "MS_UPLOAD_AIGC_MODEL = False # @param {type:\"boolean\"}\n",
    "MS_AIGC_FOUDNATION = \"FLUX_1\" # @param {\"type\":\"string\"} [\"SD_1_5\",\"SD_XL\",\"SD_3\",\"FLUX_1\"]\n",
    "MS_AIGC_MODEL_TYPE = \"Checkpoint\" # @param {\"type\":\"string\"} [\"Checkpoint\",\"LoRA\",\"VAE\"]\n",
    "MS_TAG = \"v1.0\" # @param {type:\"string\",\"placeholder\":\"MS Repo tag\"}\n",
    "\n",
    "def login_hf(hf_token: str):\n",
    "  login(token=hf_token)\n",
    "\n",
    "def list_hf_repo_tree(\n",
    "        hf_repo_id: str,\n",
    "        hf_recursive: bool = True,\n",
    "        hf_repo_type: str = \"model\",\n",
    "        hf_revision: str = \"main\"\n",
    "    ):\n",
    "  hf_repo_tree = list_repo_tree(hf_repo_id, recursive=hf_recursive, repo_type=hf_repo_type, revision=hf_revision)\n",
    "  return list(hf_repo_tree)\n",
    "\n",
    "def hf_file_download(hf_repo_id: str, hf_path: str, hf_repo_type: str, hf_revision: str,local_dir: str):\n",
    "  hf_filename = os.path.basename(hf_path)\n",
    "  hf_subfolder = os.path.dirname(hf_path)\n",
    "  hf_hub_download(hf_repo_id, hf_filename, subfolder=hf_subfolder, repo_type=hf_repo_type, revision=hf_revision, local_dir=local_dir)\n",
    "\n",
    "def ms_create_repo(\n",
    "        ms_token: str,\n",
    "        ms_repo_id: str,\n",
    "        ms_repo_private: bool,\n",
    "    ):\n",
    "  api = HubApi()\n",
    "  ms_git_token = (api.login(ms_token))[0]\n",
    "  print(f'Creating repo \"{ms_repo_id}\" on ModelScope...')\n",
    "  try:\n",
    "    api.get_model(ms_repo_id)\n",
    "    print(f'\"{ms_repo_id}\" already exist on ModelScope!')\n",
    "  except Exception:\n",
    "    model_visibility = ModelVisibility.PRIVATE if ms_repo_private else ModelVisibility.PUBLIC\n",
    "    api.create_model(ms_repo_id, license=\"Other\",visibility=model_visibility)\n",
    "    print(f'\"{ms_repo_id}\" created on ModelScope')\n",
    "\n",
    "  return ms_git_token\n",
    "\n",
    "def ms_git_clone_repo(ms_git_token, ms_repo_id, ms_revision):\n",
    "  os.chdir(WORKSPACE)\n",
    "  repo_on_local_path = os.path.join(WORKSPACE, os.path.basename(ms_repo_id))\n",
    "  print('Disabling Git LFS...')\n",
    "  os.environ[\"GIT_LFS_SKIP_SMUDGE\"] = \"1\"\n",
    "  !git lfs uninstall\n",
    "  if os.path.exists(repo_on_local_path):\n",
    "    print(f'\"{repo_on_local_path}\" already exist, will delete it!!!')\n",
    "    !rm -rf \"{repo_on_local_path}\"\n",
    "\n",
    "  !git clone -b {ms_revision} http://outh2:{ms_git_token}@www.modelscope.cn/{ms_repo_id}.git {repo_on_local_path}\n",
    "  os.chdir(repo_on_local_path)\n",
    "  !git switch {ms_revision}\n",
    "  print('Enabling Git LFS...')\n",
    "  os.environ[\"GIT_LFS_SKIP_SMUDGE\"] = \"0\"\n",
    "  !git lfs install\n",
    "  return repo_on_local_path\n",
    "\n",
    "def format_file_size(size_bytes):\n",
    "  if size_bytes == 0:\n",
    "    return \"0B\"\n",
    "  size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\")\n",
    "  i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "  p = math.pow(1024, i)\n",
    "  s = round(size_bytes / p, 2)\n",
    "  return f\"{s} {size_name[i]}\"\n",
    "\n",
    "def get_non_git_lfs_files(repo_on_local):\n",
    "  hf_repo_tree = list_hf_repo_tree(hf_repo_id=HF_REPO_ID,hf_recursive=True,hf_repo_type=HF_REPO_TYPE,hf_revision=HF_REVISION)\n",
    "  file_use_git_lfs = []\n",
    "  total = len(hf_repo_tree)\n",
    "  totol_non_lfs = 0\n",
    "  for file in hf_repo_tree:\n",
    "    if type(file) == RepoFolder:\n",
    "      path = file.path\n",
    "      path_on_local = os.path.join(repo_on_local, path)\n",
    "      os.makedirs(path_on_local, exist_ok=True)\n",
    "    elif type(file) == RepoFile:\n",
    "      path = file.path\n",
    "      size = file.size\n",
    "      file_on_local = os.path.join(repo_on_local, path)\n",
    "      if size < 25 * 1024 * 1024:\n",
    "        totol_non_lfs+=1\n",
    "        print(f'Processing {totol_non_lfs}/{total}: {path}...')\n",
    "        if os.path.exists(file_on_local):\n",
    "          print(f'\"{file_on_local}\" already exist, will delete it!!!')\n",
    "          !rm -rf \"{file_on_local}\"\n",
    "        hf_file_download(HF_REPO_ID, path, HF_REPO_TYPE, HF_REVISION, repo_on_local)\n",
    "        if os.path.exists(os.path.join(repo_on_local, \".huggingface\")):\n",
    "          !rm -rf {os.path.join(repo_on_local, \".huggingface\")}\n",
    "        if os.path.exists(os.path.join(repo_on_local, \".cache\")):\n",
    "          !rm -rf {os.path.join(repo_on_local, \".cache\")}\n",
    "\n",
    "      else:\n",
    "        print(f'\"{path}\" is {format_file_size(size)},  will add it to Git LFS list.')\n",
    "        file_use_git_lfs.append(path)\n",
    "        print(file_use_git_lfs)\n",
    "  return file_use_git_lfs, total, totol_non_lfs\n",
    "\n",
    "def upload_git_lfs_files(ms_git_token, file_use_git_lfs, total, totol_non_lfs):\n",
    "  print(f'Total non Git-LFS files: {totol_non_lfs}.')\n",
    "  i = totol_non_lfs\n",
    "  for file in file_use_git_lfs:\n",
    "    i+=1\n",
    "    repo_on_local = ms_git_clone_repo(ms_git_token, MS_REPO_ID, MS_REVISION)\n",
    "    file_on_local = os.path.join(repo_on_local, file)\n",
    "\n",
    "    if os.path.exists(file_on_local):\n",
    "      print(f'\"{file_on_local}\" already exist, will delete it!!!')\n",
    "      !rm -rf \"{file_on_local}\"\n",
    "    print(f'Processing {i}/{total}: {file}...')\n",
    "    os.chdir(repo_on_local)\n",
    "    hf_file_download(HF_REPO_ID, file, HF_REPO_TYPE, HF_REVISION, repo_on_local)\n",
    "    if os.path.exists(os.path.join(repo_on_local, \".huggingface\")):\n",
    "      !rm -rf {os.path.join(repo_on_local, \".huggingface\")}\n",
    "    if os.path.exists(os.path.join(repo_on_local, \".cache\")):\n",
    "      !rm -rf {os.path.join(repo_on_local, \".cache\")}\n",
    "    !git lfs track {file_on_local}\n",
    "    !git add {file_on_local}\n",
    "    git_commit_cmd = f'git commit -m \"{MS_COMMIT}\"'\n",
    "    !{git_commit_cmd}\n",
    "    !git push --set-upstream origin {MS_REVISION}\n",
    "    os.chdir(WORKSPACE)\n",
    "\n",
    "  total_lfs = len(file_use_git_lfs)\n",
    "  print(f'Total Git-LFS files: {total_lfs}.')\n",
    "  print(f'Total files: {total}.')\n",
    "\n",
    "def civitai_download(repo_on_local):\n",
    "  def request_get(\n",
    "    url:str,\n",
    "    headers:dict | None=None\n",
    "    ) -> tuple[Literal[True], requests.Response] | tuple[Literal[False], str]:\n",
    "    \"\"\"\n",
    "    Performs a GET request\n",
    "\n",
    "    returns: tuple(success:bool, response:Response or failure message:str)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            url,\n",
    "            stream=True,\n",
    "            verify=False,\n",
    "            headers=headers,\n",
    "        )\n",
    "\n",
    "    except TimeoutError:\n",
    "        output = f\"GET Request timed out for {url}\"\n",
    "        print(output)\n",
    "        return False, output\n",
    "\n",
    "    if not response.ok:\n",
    "        status_code = response.status_code\n",
    "        reason = response.reason\n",
    "        print(\n",
    "            f\"\"\"\n",
    "            GET Request failed with error code:\n",
    "            {status_code}: {reason}\n",
    "            \"\"\"\n",
    "        )\n",
    "        return False, reason\n",
    "\n",
    "    return True, response\n",
    "\n",
    "  if \"https://civitai.com\" in DOWNLOAD_LINK:\n",
    "    headers = {\"Authorization\": f\"Bearer {CIVITAI_TOKEN}\"}\n",
    "    success, response = request_get(DOWNLOAD_LINK, headers=headers)\n",
    "    if not success:\n",
    "      print(f'Download failed: {response}')\n",
    "      return None\n",
    "    else:\n",
    "      if DOWNLOAD_FILENAME:\n",
    "        filename = DOWNLOAD_FILENAME\n",
    "      else:\n",
    "        filename = response.headers.get(\"Content-Disposition\").split('\"')[1]\n",
    "      print(f'Downloading {filename} from CIVITAI...')\n",
    "      !aria2c --console-log-level=error --summary-interval=10 -c -x 8 -k 2M -s 8 -d {repo_on_local} -o {filename} \"{DOWNLOAD_LINK}&token={CIVITAI_TOKEN}\"\n",
    "      print(f'{filename} from CIVITAI downloaded.')\n",
    "    return filename\n",
    "  elif \"liblib\" in DOWNLOAD_LINK:\n",
    "    success, response = request_get(DOWNLOAD_LINK)\n",
    "    if not success:\n",
    "      print(f'Download failed: {response}')\n",
    "      return None\n",
    "    else:\n",
    "      if DOWNLOAD_FILENAME:\n",
    "        filename = DOWNLOAD_FILENAME\n",
    "      else:\n",
    "        filename = response.headers.get(\"Content-Disposition\").split('=')[1]\n",
    "      print(f'Downloading {filename} from LibLib...')\n",
    "      !aria2c --console-log-level=error --summary-interval=10 -c -x 8 -k 2M -s 8 -d {repo_on_local} -o {filename} \"{DOWNLOAD_LINK}\"\n",
    "      print(f'{filename} from LibLib downloaded.')\n",
    "      return filename\n",
    "  else:\n",
    "    if DOWNLOAD_FILENAME:\n",
    "      filename = DOWNLOAD_FILENAME\n",
    "    else:\n",
    "      filename = os.path.basename(DOWNLOAD_LINK)\n",
    "    !aria2c --console-log-level=error --summary-interval=10 -c -x 8 -k 2M -s 8 -d {repo_on_local} -o {filename} \"{DOWNLOAD_LINK}\"\n",
    "    return filename\n",
    "\n",
    "def get_base_model(model_type):\n",
    "  if model_type == \"SD_1_5\":\n",
    "    return \"AI-ModelScope/stable-diffusion-v1-5\"\n",
    "  elif model_type == \"SD_XL\":\n",
    "    return \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "  elif model_type == \"SD_3\":\n",
    "    return \"stabilityai/stable-diffusion-3.5-medium\"\n",
    "  elif model_type == \"FLUX_1\":\n",
    "    return \"black-forest-labs/FLUX.1-dev\"\n",
    "\n",
    "def main():\n",
    "  os.chdir(WORKSPACE)\n",
    "  !git config --global user.email \"you@example.com\"\n",
    "  !git config --global user.name \"Your Name\"\n",
    "  ms_git_token = ms_create_repo(MS_TOKEN, MS_REPO_ID, MS_REPO_PRIVATE)\n",
    "  repo_on_local = ms_git_clone_repo(ms_git_token, MS_REPO_ID, MS_REVISION)\n",
    "\n",
    "  if WORK_MODE != \"Download single file from CivitAI to Modelscope\":\n",
    "    login_hf(HF_TOKEN) if HF_TOKEN != \"\" and len(HF_TOKEN) >= 30 else print(\"HF_TOKEN Invalid, trying with out it\")\n",
    "    if WORK_MODE == \"Fork repo from Huggingface to Modelscope\":\n",
    "      file_use_git_lfs, total, totol_non_lfs = get_non_git_lfs_files(repo_on_local)\n",
    "    elif WORK_MODE == \"Fork single file from Huggingface to Modelscope\":\n",
    "      hf_hub_download(HF_REPO_ID, HF_FILENAME, subfolder=HF_SUBFOLDER if HF_SUBFOLDER else None, repo_type=HF_REPO_TYPE, revision=HF_REVISION, local_dir=repo_on_local)\n",
    "      model_name=HF_FILENAME\n",
    "  else:\n",
    "    os.chdir(repo_on_local)\n",
    "    !ls -lha | grep safetensors\n",
    "    !rm *.safetensors\n",
    "    !ls -lha | grep safetensors\n",
    "    model_name = civitai_download(repo_on_local)\n",
    "\n",
    "  os.chdir(repo_on_local)\n",
    "  !git add -A .\n",
    "  git_commit_cmd = f'git commit -m \"{MS_COMMIT}\"'\n",
    "  !{git_commit_cmd}\n",
    "  if MS_UPLOAD_AIGC_MODEL and WORK_MODE != \"Fork repo from Huggingface to Modelscope\":\n",
    "    aigc_model_config = {\"aigc_model\":True,\"framework\":\"Pytorch\",\"model_file_location\":f\"{model_name}\"}\n",
    "    with open(os.path.join(repo_on_local,\"configuration.json\"), \"w\") as j:\n",
    "      json.dump(aigc_model_config, j)\n",
    "    readme_content = f\"\"\"\n",
    "    ---\n",
    "    base_model: {get_base_model(MS_AIGC_FOUDNATION)}\n",
    "    frameworks:\n",
    "    - Pytorch\n",
    "    tasks:\n",
    "    - text-to-image-synthesis\n",
    "    license: other\n",
    "    tags:\n",
    "    - {MS_AIGC_MODEL_TYPE}\n",
    "    - text-to-image\n",
    "    vision_foundation: {MS_AIGC_FOUDNATION}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    with open(os.path.join(repo_on_local,\"README.md\"), \"w\") as f:\n",
    "      f.write(readme_content)\n",
    "    !git add -A .\n",
    "    !{git_commit_cmd}\n",
    "    !git push --set-upstream origin {MS_REVISION}\n",
    "    print(f'Repo \"{MS_REPO_ID}\" pushed to remote server.')\n",
    "    print(f'Creating tag \"{MS_TAG}\"...')\n",
    "    !git tag {MS_TAG}\n",
    "    print(f'Pushing tag \"{MS_TAG}\"...')\n",
    "    !git push --set-upstream origin {MS_TAG}\n",
    "    print(f'Tag \"{MS_TAG}\" pushed to remote server.')\n",
    "  !git push --set-upstream origin {MS_REVISION}\n",
    "  print(f'Repo \"{MS_REPO_ID}\" pushed to remote server.')\n",
    "\n",
    "  if WORK_MODE == \"Fork repo from Huggingface to Modelscope\":\n",
    "    upload_git_lfs_files(ms_git_token, file_use_git_lfs, total, totol_non_lfs)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
